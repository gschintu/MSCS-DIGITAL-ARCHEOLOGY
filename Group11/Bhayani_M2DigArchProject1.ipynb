{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from re import split, sub\n",
        "from requests import get\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\") + [\"ut\", \"'re\", \".\", \",\", \"--\", \"'s\", \"?\", \"(\", \")\", \":\", \"'\", '\"', \"-\", \"{\", \"}\", \"&\", \"|\", u\"\\u2014\"]\n",
        "\n",
        "books = {}\n",
        "book_contents = {}\n",
        "book_word_frequencies = {}\n",
        "book_word_distributions = {}\n",
        "book_bucketed_word_distributions = {}\n",
        "\n",
        "def get_book(URL, book_name):\n",
        "    # Get book\n",
        "    book = get(URL).text\n",
        "\n",
        "    # Clean html\n",
        "    book = BeautifulSoup(book, \"html.parser\").get_text()\n",
        "\n",
        "    # Save to globals\n",
        "    books[book_name] = book\n",
        "\n",
        "def get_book_contents(book_name):\n",
        "    if book_name not in books:\n",
        "        raise \"Get book by calling get_book first\"\n",
        "\n",
        "    contents = books[book_name].lower()\n",
        "    contents = split(\"\\s+\", contents)\n",
        "    for i, word in enumerate(contents):\n",
        "        word = sub('[,\"\\.\\'&\\|:@>*;/=]', \"\", word)\n",
        "        contents[i] = sub('^[0-9\\.]*$', \"\", word)\n",
        "\n",
        "    book_contents[book_name] = contents\n",
        "\n",
        "    if book_name in book_word_frequencies:\n",
        "        del book_word_frequencies[book_name]\n",
        "\n",
        "def get_book_word_frequencies(book_name):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    word_frequencies = Counter(book_contents[book_name])\n",
        "    for word in stop_words:\n",
        "        word_frequencies.pop(word, None)\n",
        "    book_word_frequencies[book_name] = word_frequencies\n",
        "\n",
        "    if book_name in book_word_distributions:\n",
        "        del book_word_distributions[book_name]\n",
        "\n",
        "    if book_name in book_bucketed_word_distributions:\n",
        "        del book_bucketed_word_distributions[book_name]\n",
        "\n",
        "def get_all_book_info(URL, book_name):\n",
        "    get_book(URL, book_name)\n",
        "    get_book_contents(book_name)\n",
        "    get_book_word_frequencies(book_name)\n",
        "\n",
        "def get_total_word_count(book_name):\n",
        "    if book_name not in book_word_frequencies:\n",
        "        raise \"Get book word frequencies by calling get_book_word_frequencies first\"\n",
        "\n",
        "    return book_word_frequencies[book_name].total()\n",
        "\n",
        "def get_n_most_common(book_name, n):\n",
        "    if book_name not in book_word_frequencies:\n",
        "        raise \"Get book word frequencies by calling get_book_word_frequencies first\"\n",
        "\n",
        "    return book_word_frequencies[book_name].most_common(n)\n",
        "\n",
        "def find_word_distribution(book_name, word):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    if book_name in book_word_distributions:\n",
        "        if word in book_word_distributions[book_name]:\n",
        "            return book_word_distributions[book_name][word]\n",
        "\n",
        "    indicies = [i for i, book_word in enumerate(book_contents[book_name]) if book_word == word]\n",
        "    book_word_distributions[book_name] = {}\n",
        "    book_word_distributions[book_name][word] = indicies\n",
        "    return indicies\n",
        "\n",
        "def find_bucketed_word_distribution(book_name, word, bucket_size):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    if book_name in book_bucketed_word_distributions:\n",
        "        if word in book_bucketed_word_distributions[book_name]:\n",
        "            if bucket_size in book_bucketed_word_distributions[book_name][word]:\n",
        "                return book_bucketed_word_distributions[book_name][word][bucket_size]\n",
        "\n",
        "    indicies = find_word_distribution(book_name, word)\n",
        "    buckets = [0 for i in range(((len(book_contents[book_name]) - 1) // bucket_size) + 1)]\n",
        "    for index in indicies:\n",
        "        buckets[index // bucket_size] += 1\n",
        "\n",
        "    book_bucketed_word_distributions[book_name] = {}\n",
        "    book_bucketed_word_distributions[book_name][word] = {}\n",
        "    book_bucketed_word_distributions[book_name][word][bucket_size] = buckets\n",
        "    return buckets\n",
        "\n",
        "def get_window_around_word(book_name, index, n):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    start = max(index - n, 0)\n",
        "    end = min(index + n + 1, len(book_contents[book_name]) - 1)\n",
        "\n",
        "    return book_contents[book_name][start:end]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzEgciLBv80K",
        "outputId": "5c0a06e0-55bd-4c33-a82e-b0f11d5f61bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_1 = \"Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/84.txt.utf-8\", book_1)"
      ],
      "metadata": {
        "id": "EY-EUTAj8vWL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_1))\n",
        "print(get_n_most_common(book_1, 15))\n",
        "print(find_bucketed_word_distribution(book_1, \"creature\", 5000))\n",
        "print(get_window_around_word(book_1, 18025, 25))\n",
        "print(get_window_around_word(book_1, 24727, 25))\n",
        "print(get_window_around_word(book_1, 40983, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUkmCVpDdZH",
        "outputId": "86f97e07-6c30-45a3-e217-4c3f61a9afc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36858\n",
            "[('one', 199), ('could', 197), ('would', 183), ('yet', 149), ('upon', 128), ('man', 123), ('may', 112), ('first', 108), ('life', 108), ('might', 108), ('father', 108), ('every', 106), ('shall', 105), ('eyes', 103), ('said', 102)]\n",
            "[3, 2, 0, 4, 2, 3, 8, 0, 2, 5, 2, 2, 2, 2, 4, 0]\n",
            "['to', 'give', 'her', 'an', 'education', 'superior', 'to', 'that', 'which', 'she', 'had', 'at', 'first', 'intended', 'this', 'benefit', 'was', 'fully', 'repaid', 'justine', 'was', 'the', 'most', 'grateful', 'little', 'creature', 'in', 'the', 'world', 'i', 'do', 'not', 'mean', 'that', 'she', 'made', 'any', 'professions', 'i', 'never', 'heard', 'one', 'pass', 'her', 'lips', 'but', 'you', 'could', 'see', 'by', 'her']\n",
            "['even', 'long', 'before', 'his', 'birth', 'it', 'may', 'therefore', 'be', 'judged', 'indecent', 'in', 'me', 'to', 'come', 'forward', 'on', 'this', 'occasion', 'but', 'when', 'i', 'see', 'a', 'fellow', 'creature', 'about', 'to', 'perish', 'through', 'the', 'cowardice', 'of', 'her', 'pretended', 'friends', 'i', 'wish', 'to', 'be', 'allowed', 'to', 'speak', 'that', 'i', 'may', 'say', 'what', 'i', 'know', 'of']\n",
            "['in', 'existence', 'but', 'his', 'state', 'was', 'far', 'different', 'from', 'mine', 'in', 'every', 'other', 'respect', 'he', 'had', 'come', 'forth', 'from', 'the', 'hands', 'of', 'god', 'a', 'perfect', 'creature', 'happy', 'and', 'prosperous', 'guarded', 'by', 'the', 'especial', 'care', 'of', 'his', 'creator', 'he', 'was', 'allowed', 'to', 'converse', 'with', 'and', 'acquire', 'knowledge', 'from', 'beings', 'of', 'a', 'superior']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_2 = \"The Great Gatsby by F. Scott Fitzgerald\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/64317.txt.utf-8\", book_2)"
      ],
      "metadata": {
        "id": "jJS8-Y3B87RM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_2))\n",
        "print(get_n_most_common(book_2, 15))\n",
        "print(find_bucketed_word_distribution(book_2, \"jay\", 5000))\n",
        "print(get_window_around_word(book_2, 18026, 25))\n",
        "print(get_window_around_word(book_2, 26061, 25))\n",
        "print(get_window_around_word(book_2, 26935, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsQb3R8LD844",
        "outputId": "00ce010b-a363-4a87-f0ab-6a1716c3e2b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27327\n",
            "[('said', 232), ('gatsby', 175), ('“i', 175), ('tom', 163), ('one', 135), ('daisy', 135), ('like', 116), ('came', 108), ('back', 105), ('little', 102), ('went', 90), ('man', 86), ('project', 85), ('house', 85), ('eyes', 85)]\n",
            "[0, 0, 1, 2, 1, 4, 0, 1, 0, 0, 0]\n",
            "['the', 'faintest', 'idea', 'what', '“this', 'matter”', 'was', 'but', 'i', 'was', 'more', 'annoyed', 'than', 'interested', 'i', 'hadn’t', 'asked', 'jordan', 'to', 'tea', 'in', 'order', 'to', 'discuss', 'mr', 'jay', 'gatsby', 'i', 'was', 'sure', 'the', 'request', 'would', 'be', 'something', 'utterly', 'fantastic', 'and', 'for', 'a', 'moment', 'i', 'was', 'sorry', 'i’d', 'ever', 'set', 'foot', 'upon', 'his', 'overpopulated']\n",
            "['gatz', 'who', 'had', 'been', 'loafing', 'along', 'the', 'beach', 'that', 'afternoon', 'in', 'a', 'torn', 'green', 'jersey', 'and', 'a', 'pair', 'of', 'canvas', 'pants', 'but', 'it', 'was', 'already', 'jay', 'gatsby', 'who', 'borrowed', 'a', 'rowboat', 'pulled', 'out', 'to', 'the', 'tuolomee', 'and', 'informed', 'cody', 'that', 'a', 'wind', 'might', 'catch', 'him', 'and', 'break', 'him', 'up', 'in', 'half']\n",
            "['against', 'him', 'but', 'what', 'remained', 'of', 'the', 'millions', 'went', 'intact', 'to', 'ella', 'kaye', 'he', 'was', 'left', 'with', 'his', 'singularly', 'appropriate', 'education', 'the', 'vague', 'contour', 'of', 'jay', 'gatsby', 'had', 'filled', 'out', 'to', 'the', 'substantiality', 'of', 'a', 'man', '------------------------------------------------------------------------', 'he', 'told', 'me', 'all', 'this', 'very', 'much', 'later', 'but', 'i’ve', 'put', 'it', 'down', 'here']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_3 = \"Alice's Adventures in Wonderland by Lewis Carroll\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/11.txt.utf-8\", book_3)"
      ],
      "metadata": {
        "id": "_8sZ8qla9E53"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_3))\n",
        "print(get_n_most_common(book_3, 15))\n",
        "print(find_bucketed_word_distribution(book_3, \"alice\", 3000))\n",
        "print(get_window_around_word(book_3, 514, 25))\n",
        "print(get_window_around_word(book_3, 9033, 25))\n",
        "print(get_window_around_word(book_3, 25617, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfnV9-4aEP3g",
        "outputId": "2d8267db-c2ed-45d8-d954-91a07812f2ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15785\n",
            "[('said', 455), ('alice', 374), ('little', 124), ('“i', 119), ('', 88), ('one', 88), ('project', 83), ('went', 83), ('like', 78), ('could', 75), ('thought', 73), ('would', 72), ('see', 65), ('queen', 64), ('know', 61)]\n",
            "[29, 37, 34, 44, 59, 55, 56, 34, 26, 0]\n",
            "['she', 'was', 'to', 'get', 'out', 'again', 'the', 'rabbit-hole', 'went', 'straight', 'on', 'like', 'a', 'tunnel', 'for', 'some', 'way', 'and', 'then', 'dipped', 'suddenly', 'down', 'so', 'suddenly', 'that', 'alice', 'had', 'not', 'a', 'moment', 'to', 'think', 'about', 'stopping', 'herself', 'before', 'she', 'found', 'herself', 'falling', 'down', 'a', 'very', 'deep', 'well', 'either', 'the', 'well', 'was', 'very', 'deep']\n",
            "['i', 'should', 'think', 'you’ll', 'feel', 'it', 'a', 'little', 'queer', 'won’t', 'you?”', '“not', 'a', 'bit”', 'said', 'the', 'caterpillar', '“well', 'perhaps', 'your', 'feelings', 'may', 'be', 'different”', 'said', 'alice', '“all', 'i', 'know', 'is', 'it', 'would', 'feel', 'very', 'queer', 'to', '_me_”', '“you!”', 'said', 'the', 'caterpillar', 'contemptuously', '“who', 'are', '_you?_”', 'which', 'brought', 'them', 'back', 'again', 'to']\n",
            "['of', 'evidence', 'we’ve', 'heard', 'yet”', 'said', 'the', 'king', 'rubbing', 'his', 'hands', '“so', 'now', 'let', 'the', 'jury—”', '“if', 'any', 'one', 'of', 'them', 'can', 'explain', 'it”', 'said', 'alice', '(she', 'had', 'grown', 'so', 'large', 'in', 'the', 'last', 'few', 'minutes', 'that', 'she', 'wasn’t', 'a', 'bit', 'afraid', 'of', 'interrupting', 'him)', '“i’ll', 'give', 'him', 'sixpence', '_i_', 'don’t']\n"
          ]
        }
      ]
    }
  ]
}