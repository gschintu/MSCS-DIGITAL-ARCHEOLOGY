{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from re import split, sub\n",
        "from requests import get\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\") + [\"ut\", \"'re\", \".\", \",\", \"--\", \"'s\", \"?\", \"(\", \")\", \":\", \"'\", '\"', \"-\", \"{\", \"}\", \"&\", \"|\", u\"\\u2014\"]\n",
        "\n",
        "books = {}\n",
        "book_contents = {}\n",
        "book_word_frequencies = {}\n",
        "book_word_distributions = {}\n",
        "book_bucketed_word_distributions = {}\n",
        "\n",
        "def get_book(URL, book_name):\n",
        "    # Get book\n",
        "    book = get(URL).text\n",
        "\n",
        "    # Clean html\n",
        "    book = BeautifulSoup(book, \"html.parser\").get_text()\n",
        "\n",
        "    # Save to globals\n",
        "    books[book_name] = book\n",
        "\n",
        "def get_book_contents(book_name):\n",
        "    if book_name not in books:\n",
        "        raise \"Get book by calling get_book first\"\n",
        "\n",
        "    contents = books[book_name].lower()\n",
        "    contents = split(\"\\s+\", contents)\n",
        "    for i, word in enumerate(contents):\n",
        "        word = sub('[,\"\\.\\'&\\|:@>*;/=]', \"\", word)\n",
        "        contents[i] = sub('^[0-9\\.]*$', \"\", word)\n",
        "\n",
        "    book_contents[book_name] = contents\n",
        "\n",
        "    if book_name in book_word_frequencies:\n",
        "        del book_word_frequencies[book_name]\n",
        "\n",
        "def get_book_word_frequencies(book_name):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    word_frequencies = Counter(book_contents[book_name])\n",
        "    for word in stop_words:\n",
        "        word_frequencies.pop(word, None)\n",
        "    book_word_frequencies[book_name] = word_frequencies\n",
        "\n",
        "    if book_name in book_word_distributions:\n",
        "        del book_word_distributions[book_name]\n",
        "\n",
        "    if book_name in book_bucketed_word_distributions:\n",
        "        del book_bucketed_word_distributions[book_name]\n",
        "\n",
        "def get_all_book_info(URL, book_name):\n",
        "    get_book(URL, book_name)\n",
        "    get_book_contents(book_name)\n",
        "    get_book_word_frequencies(book_name)\n",
        "\n",
        "def get_total_word_count(book_name):\n",
        "    if book_name not in book_word_frequencies:\n",
        "        raise \"Get book word frequencies by calling get_book_word_frequencies first\"\n",
        "\n",
        "    return book_word_frequencies[book_name].total()\n",
        "\n",
        "def get_n_most_common(book_name, n):\n",
        "    if book_name not in book_word_frequencies:\n",
        "        raise \"Get book word frequencies by calling get_book_word_frequencies first\"\n",
        "\n",
        "    return book_word_frequencies[book_name].most_common(n)\n",
        "\n",
        "def find_word_distribution(book_name, word):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    if book_name in book_word_distributions:\n",
        "        if word in book_word_distributions[book_name]:\n",
        "            return book_word_distributions[book_name][word]\n",
        "\n",
        "    indicies = [i for i, book_word in enumerate(book_contents[book_name]) if book_word == word]\n",
        "    book_word_distributions[book_name] = {}\n",
        "    book_word_distributions[book_name][word] = indicies\n",
        "    return indicies\n",
        "\n",
        "def find_bucketed_word_distribution(book_name, word, bucket_size):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    if book_name in book_bucketed_word_distributions:\n",
        "        if word in book_bucketed_word_distributions[book_name]:\n",
        "            if bucket_size in book_bucketed_word_distributions[book_name][word]:\n",
        "                return book_bucketed_word_distributions[book_name][word][bucket_size]\n",
        "\n",
        "    indicies = find_word_distribution(book_name, word)\n",
        "    buckets = [0 for i in range(((len(book_contents[book_name]) - 1) // bucket_size) + 1)]\n",
        "    for index in indicies:\n",
        "        buckets[index // bucket_size] += 1\n",
        "\n",
        "    book_bucketed_word_distributions[book_name] = {}\n",
        "    book_bucketed_word_distributions[book_name][word] = {}\n",
        "    book_bucketed_word_distributions[book_name][word][bucket_size] = buckets\n",
        "    return buckets\n",
        "\n",
        "def get_window_around_word(book_name, index, n):\n",
        "    if book_name not in book_contents:\n",
        "        raise \"Get book contents by calling get_book_contents first\"\n",
        "\n",
        "    start = max(index - n, 0)\n",
        "    end = min(index + n + 1, len(book_contents[book_name]) - 1)\n",
        "\n",
        "    return book_contents[book_name][start:end]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzEgciLBv80K",
        "outputId": "291992b7-9508-40ed-a7a4-998752053d47"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_1 = \"Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/84.txt.utf-8\", book_1)"
      ],
      "metadata": {
        "id": "EY-EUTAj8vWL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_1))\n",
        "print(get_n_most_common(book_1, 15))\n",
        "print(find_bucketed_word_distribution(book_1, \"creature\", 5000))\n",
        "print(get_window_around_word(book_1, 18025, 25))\n",
        "print(get_window_around_word(book_1, 24727, 25))\n",
        "print(get_window_around_word(book_1, 40983, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUkmCVpDdZH",
        "outputId": "45248562-9688-4a66-c69a-b06d89c2b46e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36858\n",
            "[('one', 199), ('could', 197), ('would', 183), ('yet', 149), ('upon', 128), ('man', 123), ('may', 112), ('first', 108), ('life', 108), ('might', 108), ('father', 108), ('every', 106), ('shall', 105), ('eyes', 103), ('said', 102)]\n",
            "[3, 2, 0, 4, 2, 3, 8, 0, 2, 5, 2, 2, 2, 2, 4, 0]\n",
            "['to', 'give', 'her', 'an', 'education', 'superior', 'to', 'that', 'which', 'she', 'had', 'at', 'first', 'intended', 'this', 'benefit', 'was', 'fully', 'repaid', 'justine', 'was', 'the', 'most', 'grateful', 'little', 'creature', 'in', 'the', 'world', 'i', 'do', 'not', 'mean', 'that', 'she', 'made', 'any', 'professions', 'i', 'never', 'heard', 'one', 'pass', 'her', 'lips', 'but', 'you', 'could', 'see', 'by', 'her']\n",
            "['even', 'long', 'before', 'his', 'birth', 'it', 'may', 'therefore', 'be', 'judged', 'indecent', 'in', 'me', 'to', 'come', 'forward', 'on', 'this', 'occasion', 'but', 'when', 'i', 'see', 'a', 'fellow', 'creature', 'about', 'to', 'perish', 'through', 'the', 'cowardice', 'of', 'her', 'pretended', 'friends', 'i', 'wish', 'to', 'be', 'allowed', 'to', 'speak', 'that', 'i', 'may', 'say', 'what', 'i', 'know', 'of']\n",
            "['in', 'existence', 'but', 'his', 'state', 'was', 'far', 'different', 'from', 'mine', 'in', 'every', 'other', 'respect', 'he', 'had', 'come', 'forth', 'from', 'the', 'hands', 'of', 'god', 'a', 'perfect', 'creature', 'happy', 'and', 'prosperous', 'guarded', 'by', 'the', 'especial', 'care', 'of', 'his', 'creator', 'he', 'was', 'allowed', 'to', 'converse', 'with', 'and', 'acquire', 'knowledge', 'from', 'beings', 'of', 'a', 'superior']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_2 = \"The Great Gatsby by F. Scott Fitzgerald\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/64317.txt.utf-8\", book_2)"
      ],
      "metadata": {
        "id": "jJS8-Y3B87RM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_2))\n",
        "print(get_n_most_common(book_2, 15))\n",
        "print(find_bucketed_word_distribution(book_2, \"jay\", 5000))\n",
        "print(get_window_around_word(book_1, 18026, 25))\n",
        "print(get_window_around_word(book_1, 26061, 25))\n",
        "print(get_window_around_word(book_1, 26935, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsQb3R8LD844",
        "outputId": "628ce318-0900-41ec-9d13-d930faeb9bf7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27327\n",
            "[('said', 232), ('gatsby', 175), ('“i', 175), ('tom', 163), ('one', 135), ('daisy', 135), ('like', 116), ('came', 108), ('back', 105), ('little', 102), ('went', 90), ('man', 86), ('project', 85), ('house', 85), ('eyes', 85)]\n",
            "[0, 0, 1, 2, 1, 4, 0, 1, 0, 0, 0]\n",
            "['give', 'her', 'an', 'education', 'superior', 'to', 'that', 'which', 'she', 'had', 'at', 'first', 'intended', 'this', 'benefit', 'was', 'fully', 'repaid', 'justine', 'was', 'the', 'most', 'grateful', 'little', 'creature', 'in', 'the', 'world', 'i', 'do', 'not', 'mean', 'that', 'she', 'made', 'any', 'professions', 'i', 'never', 'heard', 'one', 'pass', 'her', 'lips', 'but', 'you', 'could', 'see', 'by', 'her', 'eyes']\n",
            "['awful', 'boundary', 'between', 'life', 'and', 'death', 'felt', 'not', 'as', 'i', 'did', 'such', 'deep', 'and', 'bitter', 'agony', 'i', 'gnashed', 'my', 'teeth', 'and', 'ground', 'them', 'together', 'uttering', 'a', 'groan', 'that', 'came', 'from', 'my', 'inmost', 'soul', 'justine', 'started', 'when', 'she', 'saw', 'who', 'it', 'was', 'she', 'approached', 'me', 'and', 'said', '“dear', 'sir', 'you', 'are', 'very']\n",
            "['solitude', 'my', 'father', 'observed', 'with', 'pain', 'the', 'alteration', 'perceptible', 'in', 'my', 'disposition', 'and', 'habits', 'and', 'endeavoured', 'by', 'arguments', 'deduced', 'from', 'the', 'feelings', 'of', 'his', 'serene', 'conscience', 'and', 'guiltless', 'life', 'to', 'inspire', 'me', 'with', 'fortitude', 'and', 'awaken', 'in', 'me', 'the', 'courage', 'to', 'dispel', 'the', 'dark', 'cloud', 'which', 'brooded', 'over', 'me', '“do', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_3 = \"Alice's Adventures in Wonderland by Lewis Carroll\"\n",
        "get_all_book_info(\"https://www.gutenberg.org/ebooks/11.txt.utf-8\", book_3)"
      ],
      "metadata": {
        "id": "_8sZ8qla9E53"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_total_word_count(book_3))\n",
        "print(get_n_most_common(book_3, 15))\n",
        "print(find_bucketed_word_distribution(book_3, \"alice\", 3000))\n",
        "print(get_window_around_word(book_1, 514, 25))\n",
        "print(get_window_around_word(book_1, 9033, 25))\n",
        "print(get_window_around_word(book_1, 25617, 25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfnV9-4aEP3g",
        "outputId": "3275d67a-7952-491a-9b76-bfbbdf5334d6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15785\n",
            "[('said', 455), ('alice', 374), ('little', 124), ('“i', 119), ('', 88), ('one', 88), ('project', 83), ('went', 83), ('like', 78), ('could', 75), ('thought', 73), ('would', 72), ('see', 65), ('queen', 64), ('know', 61)]\n",
            "[29, 37, 34, 44, 59, 55, 56, 34, 26, 0]\n",
            "['attracts', 'the', 'needle', 'and', 'may', 'regulate', 'a', 'thousand', 'celestial', 'observations', 'that', 'require', 'only', 'this', 'voyage', 'to', 'render', 'their', 'seeming', 'eccentricities', 'consistent', 'for', 'ever', 'i', 'shall', 'satiate', 'my', 'ardent', 'curiosity', 'with', 'the', 'sight', 'of', 'a', 'part', 'of', 'the', 'world', 'never', 'before', 'visited', 'and', 'may', 'tread', 'a', 'land', 'never', 'before', 'imprinted', 'by', 'the']\n",
            "['in', 'the', 'eighteenth', 'century', 'but', 'while', 'i', 'followed', 'the', 'routine', 'of', 'education', 'in', 'the', 'schools', 'of', 'geneva', 'i', 'was', 'to', 'a', 'great', 'degree', 'self-taught', 'with', 'regard', 'to', 'my', 'favourite', 'studies', 'my', 'father', 'was', 'not', 'scientific', 'and', 'i', 'was', 'left', 'to', 'struggle', 'with', 'a', 'child’s', 'blindness', 'added', 'to', 'a', 'student’s', 'thirst', 'for']\n",
            "['my', 'poor', 'girl”', 'said', 'elizabeth', '“why', 'do', 'you', 'kneel', 'if', 'you', 'are', 'innocent?', 'i', 'am', 'not', 'one', 'of', 'your', 'enemies', 'i', 'believed', 'you', 'guiltless', 'notwithstanding', 'every', 'evidence', 'until', 'i', 'heard', 'that', 'you', 'had', 'yourself', 'declared', 'your', 'guilt', 'that', 'report', 'you', 'say', 'is', 'false', 'and', 'be', 'assured', 'dear', 'justine', 'that', 'nothing', 'can']\n"
          ]
        }
      ]
    }
  ]
}